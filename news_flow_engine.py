"""
æ–°é—»æµé‡åˆ†æå¼•æ“
åŸºäº"æµé‡ä¸ºç‹"ç†å¿µçš„çŸ­çº¿ç‚’è‚¡æŒ‡å¯¼ç³»ç»Ÿ
æ•´åˆæ•°æ®è·å–ã€æµé‡æ¨¡å‹ã€æƒ…ç»ªåˆ†æã€AIåˆ†æã€é¢„è­¦ç³»ç»Ÿ
"""
import logging
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class NewsFlowEngine:
    """æ–°é—»æµé‡åˆ†æå¼•æ“"""
    
    def __init__(self):
        """åˆå§‹åŒ–å¼•æ“"""
        # æ ¸å¿ƒæ¨¡å—
        self.fetcher = None
        self.model = None
        self.sentiment = None
        self.agents = None
        self.alerts = None
        self.db = None
        
        self._init_modules()
        logger.info("âœ… æ–°é—»æµé‡å¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    def _init_modules(self):
        """åˆå§‹åŒ–æ‰€æœ‰æ¨¡å—"""
        try:
            from news_flow_data import NewsFlowDataFetcher
            self.fetcher = NewsFlowDataFetcher()
        except Exception as e:
            logger.error(f"æ•°æ®è·å–æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
        
        try:
            from news_flow_model import NewsFlowModel
            self.model = NewsFlowModel()
        except Exception as e:
            logger.error(f"æµé‡æ¨¡å‹æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
        
        try:
            from news_flow_sentiment import SentimentAnalyzer
            self.sentiment = SentimentAnalyzer()
        except Exception as e:
            logger.error(f"æƒ…ç»ªåˆ†ææ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
        
        try:
            from news_flow_agents import NewsFlowAgents
            self.agents = NewsFlowAgents()
        except Exception as e:
            logger.error(f"AIåˆ†ææ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
        
        try:
            from news_flow_alert import NewsFlowAlertSystem
            self.alerts = NewsFlowAlertSystem()
        except Exception as e:
            logger.error(f"é¢„è­¦ç³»ç»Ÿæ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
        
        try:
            from news_flow_db import news_flow_db
            self.db = news_flow_db
        except Exception as e:
            logger.error(f"æ•°æ®åº“æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def run_quick_analysis(self, platforms: List[str] = None, 
                           category: str = None) -> Dict:
        """
        è¿è¡Œå¿«é€Ÿåˆ†æï¼ˆä¸å«AIï¼‰
        
        ç”¨äºå®šæ—¶åŒæ­¥å’Œå¿«é€ŸæŸ¥çœ‹
        
        Returns:
            {
                'success': bool,
                'snapshot_id': int,
                'flow_data': Dict,
                'model_data': Dict,
                'sentiment_data': Dict,
                'stock_news': List,
                'hot_topics': List,
                'fetch_time': str,
            }
        """
        try:
            logger.info("ğŸš€ å¼€å§‹å¿«é€Ÿåˆ†æ...")
            start_time = time.time()
            
            # 1. è·å–å¤šå¹³å°æ–°é—»æ•°æ®
            logger.info("ğŸ“Š è·å–æ–°é—»æ•°æ®...")
            if not self.fetcher:
                return {'success': False, 'error': 'æ•°æ®è·å–æ¨¡å—ä¸å¯ç”¨'}
            
            multi_result = self.fetcher.get_multi_platform_news(
                platforms=platforms, category=category
            )
            
            if not multi_result['success']:
                return {'success': False, 'error': 'è·å–æ–°é—»æ•°æ®å¤±è´¥'}
            
            platforms_data = multi_result['platforms_data']
            success_count = multi_result['success_count']
            
            # 2. æå–è‚¡ç¥¨ç›¸å…³æ–°é—»
            logger.info("ğŸ” æå–è‚¡ç¥¨ç›¸å…³æ–°é—»...")
            stock_news = self.fetcher.extract_stock_related_news(platforms_data)
            
            # 3. è·å–çƒ­é—¨è¯é¢˜
            logger.info("ğŸ”¥ åˆ†æçƒ­é—¨è¯é¢˜...")
            hot_topics = self.fetcher.get_hot_topics(platforms_data, top_n=20)
            
            # 4. è®¡ç®—æµé‡å¾—åˆ†ï¼ˆåŸºç¡€ï¼‰
            logger.info("ğŸ“ˆ è®¡ç®—æµé‡å¾—åˆ†...")
            flow_data = self.fetcher.calculate_flow_score(platforms_data)
            
            # 5. è¿è¡Œæµé‡æ¨¡å‹
            logger.info("ğŸ”¬ è¿è¡Œæµé‡æ¨¡å‹...")
            history_scores = self._get_history_scores(hours=24)
            model_data = None
            if self.model:
                model_data = self.model.run_full_model(
                    platforms_data, hot_topics, history_scores
                )
            
            # 6. æƒ…ç»ªåˆ†æ
            logger.info("ğŸ’­ åˆ†æå¸‚åœºæƒ…ç»ª...")
            sentiment_data = None
            if self.sentiment:
                history_sentiments = self._get_history_sentiments(limit=10)
                sentiment_data = self.sentiment.run_full_sentiment_analysis(
                    platforms_data, stock_news, history_scores,
                    flow_data['total_score'], history_sentiments
                )
            
            # 7. ä¿å­˜åˆ°æ•°æ®åº“
            logger.info("ğŸ’¾ ä¿å­˜åˆ†æç»“æœ...")
            snapshot_id = None
            if self.db:
                snapshot_id = self.db.save_flow_snapshot(
                    flow_data, platforms_data, stock_news, hot_topics
                )
                
                # ä¿å­˜æƒ…ç»ªè®°å½•
                if sentiment_data and snapshot_id:
                    sentiment_record = {
                        'sentiment_index': sentiment_data.get('sentiment', {}).get('sentiment_index', 50),
                        'sentiment_class': sentiment_data.get('sentiment', {}).get('sentiment_class', 'ä¸­æ€§'),
                        'flow_stage': sentiment_data.get('flow_stage', {}).get('stage_name', 'æœªçŸ¥'),
                        'momentum': sentiment_data.get('momentum', {}).get('momentum', 1.0),
                        'viral_k': model_data.get('viral_k', {}).get('k_value', 1.0) if model_data else 1.0,
                        'flow_type': model_data.get('flow_type', {}).get('flow_type', 'æœªçŸ¥') if model_data else 'æœªçŸ¥',
                        'stage_analysis': sentiment_data.get('flow_stage', {}).get('analysis', ''),
                    }
                    self.db.save_sentiment_record(snapshot_id, sentiment_record)
            
            duration = time.time() - start_time
            logger.info(f"âœ… å¿«é€Ÿåˆ†æå®Œæˆï¼Œè€—æ—¶ {duration:.2f} ç§’")
            
            return {
                'success': True,
                'snapshot_id': snapshot_id,
                'success_count': success_count,
                'flow_data': flow_data,
                'model_data': model_data,
                'sentiment_data': sentiment_data,
                'stock_news': stock_news,
                'hot_topics': hot_topics,
                'platforms_data': platforms_data,
                'fetch_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'duration': round(duration, 2),
            }
            
        except Exception as e:
            logger.error(f"âŒ å¿«é€Ÿåˆ†æå¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}
    
    def run_full_analysis(self, platforms: List[str] = None, 
                          category: str = None,
                          include_ai: bool = True) -> Dict:
        """
        è¿è¡Œå®Œæ•´åˆ†æï¼ˆå«AIï¼‰
        
        Returns:
            {
                'success': bool,
                'snapshot_id': int,
                'flow_data': Dict,
                'model_data': Dict,
                'sentiment_data': Dict,
                'ai_analysis': Dict,
                'trading_signals': Dict,
                'stock_news': List,
                'hot_topics': List,
            }
        """
        try:
            logger.info("ğŸš€ å¼€å§‹å®Œæ•´åˆ†æ...")
            start_time = time.time()
            
            # 1. å…ˆè¿è¡Œå¿«é€Ÿåˆ†æ
            quick_result = self.run_quick_analysis(platforms, category)
            
            if not quick_result['success']:
                return quick_result
            
            # 2. AIæ™ºèƒ½åˆ†æ
            ai_analysis = None
            if include_ai:
                if not self.agents:
                    logger.warning("âš ï¸ AIä»£ç†æ¨¡å—æœªåˆå§‹åŒ–")
                elif not self.agents.is_available():
                    logger.warning("âš ï¸ DeepSeek APIä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®")
                else:
                    logger.info("ğŸ¤– è¿è¡ŒAIåˆ†æ...")
                    
                    model_data = quick_result.get('model_data', {})
                    sentiment_data = quick_result.get('sentiment_data', {})
                    
                    # åŸºç¡€AIåˆ†æ
                    ai_analysis = self.agents.run_full_analysis(
                        quick_result['hot_topics'],
                        quick_result['stock_news'],
                        quick_result['flow_data'],
                        sentiment_data,
                        viral_k=model_data.get('viral_k', {}).get('k_value', 1.0) if model_data else 1.0,
                        flow_type=model_data.get('flow_type', {}).get('flow_type', 'æœªçŸ¥') if model_data else 'æœªçŸ¥',
                    )
                    
                    # å¤šæ¿å—æ·±åº¦åˆ†æï¼ˆå¤šæ¬¡è°ƒç”¨DeepSeekï¼‰
                    logger.info("ğŸ” å¼€å§‹å¤šæ¿å—æ·±åº¦åˆ†æ...")
                    multi_sector_analysis = self.agents.run_multi_sector_analysis(
                        quick_result['hot_topics'],
                        quick_result['stock_news']
                    )
                    
                    # åˆå¹¶å¤šæ¿å—åˆ†æç»“æœ
                    if ai_analysis and multi_sector_analysis.get('success'):
                        ai_analysis['multi_sector'] = multi_sector_analysis
                    
                    # ä¿å­˜AIåˆ†æç»“æœ
                    if ai_analysis and self.db and quick_result.get('snapshot_id'):
                        ai_record = {
                            'affected_sectors': ai_analysis.get('sector_analysis', {}).get('benefited_sectors', []),
                            'recommended_stocks': ai_analysis.get('stock_recommend', {}).get('recommended_stocks', []),
                            'risk_level': ai_analysis.get('risk_assess', {}).get('risk_level', 'æœªçŸ¥'),
                            'risk_factors': ai_analysis.get('risk_assess', {}).get('risk_factors', []),
                            'advice': ai_analysis.get('investment_advice', {}).get('advice', 'è§‚æœ›'),
                            'confidence': ai_analysis.get('investment_advice', {}).get('confidence', 50),
                            'summary': ai_analysis.get('investment_advice', {}).get('summary', ''),
                            'model_used': 'deepseek-chat',
                            'analysis_time': ai_analysis.get('analysis_time', 0),
                        }
                        self.db.save_ai_analysis(quick_result['snapshot_id'], ai_record)
            
            # 3. ç”Ÿæˆäº¤æ˜“ä¿¡å·
            trading_signals = self._generate_trading_signals(
                quick_result.get('flow_data', {}),
                quick_result.get('model_data', {}),
                quick_result.get('sentiment_data', {}),
                ai_analysis
            )
            
            duration = time.time() - start_time
            logger.info(f"âœ… å®Œæ•´åˆ†æå®Œæˆï¼Œè€—æ—¶ {duration:.2f} ç§’")
            
            return {
                'success': True,
                'snapshot_id': quick_result.get('snapshot_id'),
                'flow_data': quick_result.get('flow_data'),
                'model_data': quick_result.get('model_data'),
                'sentiment_data': quick_result.get('sentiment_data'),
                'ai_analysis': ai_analysis,
                'trading_signals': trading_signals,
                'stock_news': quick_result.get('stock_news'),
                'hot_topics': quick_result.get('hot_topics'),
                'platforms_data': quick_result.get('platforms_data'),
                'fetch_time': quick_result.get('fetch_time'),
                'duration': round(duration, 2),
            }
            
        except Exception as e:
            logger.error(f"âŒ å®Œæ•´åˆ†æå¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}
    
    def run_alert_check(self) -> Dict:
        """
        è¿è¡Œé¢„è­¦æ£€æŸ¥
        
        Returns:
            {
                'success': bool,
                'alerts': List[Dict],
            }
        """
        try:
            logger.info("âš ï¸ å¼€å§‹é¢„è­¦æ£€æŸ¥...")
            
            if not self.alerts:
                return {'success': False, 'error': 'é¢„è­¦ç³»ç»Ÿä¸å¯ç”¨'}
            
            # è·å–å½“å‰æ•°æ®
            quick_result = self.run_quick_analysis()
            
            if not quick_result['success']:
                return {'success': False, 'error': quick_result.get('error')}
            
            # è·å–å†å²æ•°æ®
            history_data = self._get_previous_snapshot()
            
            # æ„å»ºæ£€æŸ¥æ•°æ®
            current_data = {
                'flow_data': quick_result.get('flow_data', {}),
                'hot_topics': quick_result.get('hot_topics', []),
                'viral_k': quick_result.get('model_data', {}).get('viral_k', {}),
                'flow_stage': quick_result.get('sentiment_data', {}).get('flow_stage', {}),
            }
            
            # æ£€æŸ¥é¢„è­¦
            alerts = self.alerts.check_alerts(
                current_data,
                history_data,
                quick_result.get('sentiment_data'),
                quick_result.get('snapshot_id')
            )
            
            logger.info(f"âœ… é¢„è­¦æ£€æŸ¥å®Œæˆï¼Œè§¦å‘ {len(alerts)} ä¸ªé¢„è­¦")
            
            return {
                'success': True,
                'alerts': alerts,
                'snapshot_id': quick_result.get('snapshot_id'),
            }
            
        except Exception as e:
            logger.error(f"âŒ é¢„è­¦æ£€æŸ¥å¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}
    
    def get_dashboard_data(self) -> Dict:
        """
        è·å–ä»ªè¡¨ç›˜æ•°æ®
        
        Returns:
            {
                'latest_snapshot': Dict,
                'latest_sentiment': Dict,
                'latest_ai_analysis': Dict,
                'recent_alerts': List,
                'flow_trend': Dict,
                'scheduler_status': Dict,
            }
        """
        try:
            data = {}
            
            if self.db:
                # æœ€æ–°å¿«ç…§
                data['latest_snapshot'] = self.db.get_latest_snapshot()
                
                # æœ€æ–°æƒ…ç»ª
                data['latest_sentiment'] = self.db.get_latest_sentiment()
                
                # æœ€æ–°AIåˆ†æ
                data['latest_ai_analysis'] = self.db.get_latest_ai_analysis()
                
                # æœ€è¿‘é¢„è­¦
                data['recent_alerts'] = self.db.get_alerts(days=1)
                
                # æµé‡è¶‹åŠ¿ï¼ˆ7å¤©ï¼‰
                data['flow_trend'] = self.get_flow_trend(days=7)
            
            # è°ƒåº¦å™¨çŠ¶æ€
            try:
                from news_flow_scheduler import news_flow_scheduler
                data['scheduler_status'] = news_flow_scheduler.get_status()
            except:
                data['scheduler_status'] = None
            
            return data
            
        except Exception as e:
            logger.error(f"è·å–ä»ªè¡¨ç›˜æ•°æ®å¤±è´¥: {e}")
            return {}
    
    def get_flow_trend(self, days: int = 7) -> Dict:
        """è·å–æµé‡è¶‹åŠ¿"""
        if not self.db:
            return {'dates': [], 'scores': [], 'trend': 'æ— æ•°æ®'}
        
        stats = self.db.get_daily_statistics(days)
        
        if not stats:
            return {'dates': [], 'scores': [], 'trend': 'æ— æ•°æ®', 'analysis': 'æš‚æ— å†å²æ•°æ®'}
        
        # åè½¬ï¼ˆä»æ—§åˆ°æ–°ï¼‰
        stats.reverse()
        
        dates = [s['date'] for s in stats]
        avg_scores = [s['avg_score'] for s in stats]
        max_scores = [s['max_score'] for s in stats]
        min_scores = [s['min_score'] for s in stats]
        
        # åˆ¤æ–­è¶‹åŠ¿
        if len(avg_scores) >= 3:
            recent_avg = sum(avg_scores[-3:]) / 3
            earlier_avg = sum(avg_scores[:3]) / 3
            
            if recent_avg > earlier_avg * 1.2:
                trend = 'ä¸Šå‡'
                analysis = f"è¿‘æœŸæµé‡æŒç»­ä¸Šå‡ï¼ˆè¿‘3æ—¥å‡å€¼{recent_avg:.0f} > å‰3æ—¥å‡å€¼{earlier_avg:.0f}ï¼‰ï¼Œå¸‚åœºçƒ­åº¦å‡æ¸©ã€‚"
            elif recent_avg < earlier_avg * 0.8:
                trend = 'ä¸‹é™'
                analysis = f"è¿‘æœŸæµé‡æŒç»­ä¸‹é™ï¼ˆè¿‘3æ—¥å‡å€¼{recent_avg:.0f} < å‰3æ—¥å‡å€¼{earlier_avg:.0f}ï¼‰ï¼Œå¸‚åœºçƒ­åº¦é™æ¸©ã€‚"
            else:
                trend = 'å¹³ç¨³'
                analysis = f"è¿‘æœŸæµé‡æ³¢åŠ¨ä¸å¤§ï¼ˆè¿‘3æ—¥å‡å€¼{recent_avg:.0f} â‰ˆ å‰3æ—¥å‡å€¼{earlier_avg:.0f}ï¼‰ï¼Œå¸‚åœºå¤„äºå¹³è¡¡çŠ¶æ€ã€‚"
        else:
            trend = 'æ•°æ®ä¸è¶³'
            analysis = 'å†å²æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ¤æ–­è¶‹åŠ¿'
        
        return {
            'dates': dates,
            'avg_scores': avg_scores,
            'max_scores': max_scores,
            'min_scores': min_scores,
            'trend': trend,
            'analysis': analysis,
        }
    
    def _generate_trading_signals(self, flow_data: Dict, 
                                   model_data: Dict,
                                   sentiment_data: Dict,
                                   ai_analysis: Dict = None) -> Dict:
        """ç”Ÿæˆäº¤æ˜“ä¿¡å·"""
        signals = {
            'overall_signal': 'è§‚æœ›',
            'confidence': 50,
            'risk_level': 'ä¸­ç­‰',
            'hot_sectors': [],
            'operation_advice': '',
            'key_message': '',
        }
        
        # è·å–å„é¡¹æŒ‡æ ‡
        total_score = flow_data.get('total_score', 0)
        flow_level = flow_data.get('level', 'ä¸­')
        
        sentiment_index = 50
        flow_stage = 'æœªçŸ¥'
        if sentiment_data:
            sentiment_index = sentiment_data.get('sentiment', {}).get('sentiment_index', 50)
            flow_stage = sentiment_data.get('flow_stage', {}).get('stage_name', 'æœªçŸ¥')
        
        viral_k = 1.0
        if model_data:
            viral_k = model_data.get('viral_k', {}).get('k_value', 1.0)
        
        # æ ¸å¿ƒåˆ¤æ–­é€»è¾‘
        if flow_stage in ['ä¸€è‡´', 'consensus']:
            # æµé‡é«˜æ½® = é€ƒå‘½æ—¶åˆ»
            signals['overall_signal'] = 'å–å‡º'
            signals['confidence'] = 90
            signals['risk_level'] = 'æé«˜'
            signals['key_message'] = 'âš ï¸ æµé‡é«˜æ½® = ä»·æ ¼é«˜æ½® = é€ƒå‘½æ—¶åˆ»ï¼ç«‹å³å‡ä»“æˆ–æ¸…ä»“ï¼'
            signals['operation_advice'] = 'ç«‹å³å‡ä»“æˆ–æ¸…ä»“ï¼Œé”å®šåˆ©æ¶¦ã€‚ä¸è¦è´ªå©ªï¼Œä¸è¦çŠ¹è±«ã€‚'
            
        elif flow_stage in ['é€€æ½®', 'decline']:
            signals['overall_signal'] = 'è§‚æœ›'
            signals['confidence'] = 80
            signals['risk_level'] = 'é«˜'
            signals['key_message'] = 'æµé‡é€€æ½®ï¼ŒåŠæ—¶æ­¢ç›ˆæ­¢æŸ'
            signals['operation_advice'] = 'æŒä»“è€…åŠæ—¶æ­¢ç›ˆæ­¢æŸï¼Œç©ºä»“è€…ç»§ç»­è§‚æœ›ã€‚'
            
        elif flow_stage in ['åŠ é€Ÿ', 'acceleration'] and viral_k > 1.2:
            signals['overall_signal'] = 'ä¹°å…¥'
            signals['confidence'] = 75
            signals['risk_level'] = 'ä¸­ç­‰'
            signals['key_message'] = 'æµé‡åŠ é€ŸæœŸï¼Œå¯å‚ä¸é¾™å¤´'
            signals['operation_advice'] = 'å…³æ³¨é¾™å¤´è‚¡ï¼Œè½»ä»“è¯•æ¢ã€‚è®¾ç½®æ­¢æŸä½ï¼ˆ-5%ï¼‰ï¼Œæ­¢ç›ˆä½ï¼ˆ+15%ï¼‰ã€‚'
            
        elif flow_stage in ['å¯åŠ¨', 'startup']:
            signals['overall_signal'] = 'å…³æ³¨'
            signals['confidence'] = 65
            signals['risk_level'] = 'ä½'
            signals['key_message'] = 'æµé‡å¯åŠ¨æœŸï¼Œå¯ä»¥å…³æ³¨'
            signals['operation_advice'] = 'å¯†åˆ‡å…³æ³¨ï¼Œç­‰å¾…ç¡®è®¤åä»‹å…¥ã€‚'
            
        elif flow_level == "æé«˜" and sentiment_index > 85:
            signals['overall_signal'] = 'è§‚æœ›'
            signals['confidence'] = 70
            signals['risk_level'] = 'é«˜'
            signals['key_message'] = 'æµé‡æé«˜+æƒ…ç»ªè¿‡çƒ­ï¼Œè¿½é«˜é£é™©å¤§'
            signals['operation_advice'] = 'ä¸å»ºè®®è¿½é«˜ï¼Œç­‰å¾…å›è°ƒæœºä¼šã€‚'
            
        else:
            signals['overall_signal'] = 'è§‚æœ›'
            signals['confidence'] = 50
            signals['risk_level'] = 'ä¸­ç­‰'
            signals['key_message'] = 'å¸‚åœºæ— æ˜ç¡®æ–¹å‘ï¼Œä¿æŒè§‚æœ›'
            signals['operation_advice'] = 'ä¿æŒè§‚æœ›ï¼Œç­‰å¾…æµé‡ä¿¡å·æ˜ç¡®ã€‚'
        
        # æ•´åˆAIåˆ†æç»“æœ
        if ai_analysis:
            advice = ai_analysis.get('investment_advice', {})
            if advice.get('advice'):
                signals['ai_advice'] = advice.get('advice')
                signals['ai_confidence'] = advice.get('confidence', 50)
                signals['ai_summary'] = advice.get('summary', '')
            
            sectors = ai_analysis.get('sector_analysis', {}).get('benefited_sectors', [])
            signals['hot_sectors'] = sectors[:3]
        
        return signals
    
    def _get_history_scores(self, hours: int = 24) -> List[int]:
        """è·å–å†å²æµé‡å¾—åˆ†"""
        if not self.db:
            return []
        
        scores = self.db.get_recent_scores(hours)
        return [s['total_score'] for s in scores]
    
    def _get_history_sentiments(self, limit: int = 10) -> List[Dict]:
        """è·å–å†å²æƒ…ç»ªè®°å½•"""
        if not self.db:
            return []
        
        return self.db.get_sentiment_history(limit)
    
    def _get_previous_snapshot(self) -> Optional[Dict]:
        """è·å–ä¸Šä¸€æ¬¡å¿«ç…§"""
        if not self.db:
            return None
        
        snapshots = self.db.get_history_snapshots(limit=2)
        if len(snapshots) >= 2:
            detail = self.db.get_snapshot_detail(snapshots[1]['id'])
            return {
                'hot_topics': detail.get('hot_topics', []),
                'snapshot': detail.get('snapshot', {}),
            }
        return None
    
    def compare_with_history(self, current_score: int) -> Dict:
        """ä¸å†å²æ•°æ®å¯¹æ¯”"""
        if not self.db:
            return {
                'percentile': 50,
                'level_description': 'æ— å†å²å¯¹æ¯”',
                'comparison': 'æš‚æ— è¶³å¤Ÿçš„å†å²æ•°æ®è¿›è¡Œå¯¹æ¯”'
            }
        
        stats = self.db.get_daily_statistics(30)
        
        if not stats:
            return {
                'percentile': 50,
                'level_description': 'æ— å†å²å¯¹æ¯”',
                'comparison': 'æš‚æ— è¶³å¤Ÿçš„å†å²æ•°æ®è¿›è¡Œå¯¹æ¯”'
            }
        
        all_scores = []
        for stat in stats:
            all_scores.extend([stat['avg_score'], stat['max_score'], stat['min_score']])
        
        all_scores.sort()
        
        lower_count = sum(1 for s in all_scores if s < current_score)
        percentile = int(lower_count / len(all_scores) * 100) if all_scores else 50
        
        if percentile >= 90:
            level_description = "æé«˜æ°´å¹³"
            comparison = f"å½“å‰æµé‡å¾—åˆ†{current_score}å¤„äºå†å²æé«˜æ°´å¹³ï¼ˆè¶…è¿‡{percentile}%çš„å†å²è®°å½•ï¼‰ï¼Œæµé‡æåº¦çˆ†å‘ï¼"
        elif percentile >= 70:
            level_description = "è¾ƒé«˜æ°´å¹³"
            comparison = f"å½“å‰æµé‡å¾—åˆ†{current_score}å¤„äºå†å²è¾ƒé«˜æ°´å¹³ï¼ˆè¶…è¿‡{percentile}%çš„å†å²è®°å½•ï¼‰ï¼Œæµé‡æ´»è·ƒã€‚"
        elif percentile >= 30:
            level_description = "æ­£å¸¸æ°´å¹³"
            comparison = f"å½“å‰æµé‡å¾—åˆ†{current_score}å¤„äºå†å²æ­£å¸¸æ°´å¹³ï¼ˆè¶…è¿‡{percentile}%çš„å†å²è®°å½•ï¼‰ã€‚"
        else:
            level_description = "è¾ƒä½æ°´å¹³"
            comparison = f"å½“å‰æµé‡å¾—åˆ†{current_score}å¤„äºå†å²è¾ƒä½æ°´å¹³ï¼ˆä»…è¶…è¿‡{percentile}%çš„å†å²è®°å½•ï¼‰ï¼Œæµé‡ä½è¿·ã€‚"
        
        return {
            'percentile': percentile,
            'level_description': level_description,
            'comparison': comparison
        }


# å…¨å±€å¼•æ“å®ä¾‹
news_flow_engine = NewsFlowEngine()


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("=== æµ‹è¯•æ–°é—»æµé‡åˆ†æå¼•æ“ ===")
    
    # è¿è¡Œå¿«é€Ÿåˆ†æ
    print("\n--- å¿«é€Ÿåˆ†æ ---")
    result = news_flow_engine.run_quick_analysis(category='finance')
    
    if result['success']:
        print(f"âœ… åˆ†ææˆåŠŸï¼å¿«ç…§ID: {result.get('snapshot_id')}")
        print(f"\næµé‡å¾—åˆ†: {result['flow_data']['total_score']}")
        print(f"æµé‡ç­‰çº§: {result['flow_data']['level']}")
        print(f"è‚¡ç¥¨ç›¸å…³æ–°é—»: {len(result['stock_news'])} æ¡")
        print(f"çƒ­é—¨è¯é¢˜: {len(result['hot_topics'])} ä¸ª")
        
        if result.get('sentiment_data'):
            sentiment = result['sentiment_data'].get('sentiment', {})
            print(f"\næƒ…ç»ªæŒ‡æ•°: {sentiment.get('sentiment_index', 'N/A')}")
            print(f"æƒ…ç»ªåˆ†ç±»: {sentiment.get('sentiment_class', 'N/A')}")
            
            flow_stage = result['sentiment_data'].get('flow_stage', {})
            print(f"æµé‡é˜¶æ®µ: {flow_stage.get('stage_name', 'N/A')}")
    else:
        print(f"âŒ åˆ†æå¤±è´¥: {result.get('error')}")
